{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfed9f4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4069fb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\gasse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gasse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\gasse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gasse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Core libraries\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('brown')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad659d",
   "metadata": {},
   "source": [
    "# Sample Test Phrases (English & Arabic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6ed7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHRASES = [\n",
    "    'I love you',\n",
    "    'I hate you',\n",
    "    \"it's too expensive\",\n",
    "    'this is a wonderful film',\n",
    "    \"I like the phone but it's expensive\",\n",
    "    \"I'll never buy this again\",\n",
    "    'هذا مطعم رائع',\n",
    "    'هذا المنتج سء',\n",
    "    'لن اشتري منه مرة أخري',\n",
    "    'كلام فاضي'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c9e36",
   "metadata": {},
   "source": [
    "# VADER Sentiment Analysis (NLTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "977b1be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you → {'Negative': 0.0, 'Neutral': 0.192, 'Positive': 0.808, 'Compound': 0.6369}\n",
      "--------------------------------------------------------------------\n",
      "I hate you → {'Negative': 0.787, 'Neutral': 0.213, 'Positive': 0.0, 'Compound': -0.5719}\n",
      "--------------------------------------------------------------------\n",
      "it's too expensive → {'Negative': 0.0, 'Neutral': 1.0, 'Positive': 0.0, 'Compound': 0.0}\n",
      "--------------------------------------------------------------------\n",
      "this is a wonderful film → {'Negative': 0.0, 'Neutral': 0.448, 'Positive': 0.552, 'Compound': 0.5719}\n",
      "--------------------------------------------------------------------\n",
      "I like the phone but it's expensive → {'Negative': 0.0, 'Neutral': 0.741, 'Positive': 0.259, 'Compound': 0.1901}\n",
      "--------------------------------------------------------------------\n",
      "I'll never buy this again → {'Negative': 0.0, 'Neutral': 1.0, 'Positive': 0.0, 'Compound': 0.0}\n",
      "--------------------------------------------------------------------\n",
      "هذا مطعم رائع → {'Negative': 0.0, 'Neutral': 1.0, 'Positive': 0.0, 'Compound': 0.0}\n",
      "--------------------------------------------------------------------\n",
      "هذا المنتج سء → {'Negative': 0.0, 'Neutral': 1.0, 'Positive': 0.0, 'Compound': 0.0}\n",
      "--------------------------------------------------------------------\n",
      "لن اشتري منه مرة أخري → {'Negative': 0.0, 'Neutral': 1.0, 'Positive': 0.0, 'Compound': 0.0}\n",
      "--------------------------------------------------------------------\n",
      "كلام فاضي → {'Negative': 0.0, 'Neutral': 1.0, 'Positive': 0.0, 'Compound': 0.0}\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sa_vader(text):\n",
    "    scores = sia.polarity_scores(text)\n",
    "    return {\n",
    "        \"Negative\": scores[\"neg\"],\n",
    "        \"Neutral\": scores[\"neu\"],\n",
    "        \"Positive\": scores[\"pos\"],\n",
    "        \"Compound\": scores[\"compound\"]\n",
    "    }\n",
    "\n",
    "# Test VADER\n",
    "for p in PHRASES:\n",
    "    print(f\"{p} → {sa_vader(p)}\")\n",
    "    print (\"--------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd38d91",
   "metadata": {},
   "source": [
    "# TextBlob Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aae6406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install textblob\n",
    "install(\"textblob\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d5455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you → Polarity: 0.5\n",
      "--------------------------------------------------------------------\n",
      "I hate you → Polarity: -0.8\n",
      "--------------------------------------------------------------------\n",
      "it's too expensive → Polarity: -0.5\n",
      "--------------------------------------------------------------------\n",
      "this is a wonderful film → Polarity: 1.0\n",
      "--------------------------------------------------------------------\n",
      "I like the phone but it's expensive → Polarity: -0.5\n",
      "--------------------------------------------------------------------\n",
      "I'll never buy this again → Polarity: 0.0\n",
      "--------------------------------------------------------------------\n",
      "هذا مطعم رائع → Polarity: 0.0\n",
      "--------------------------------------------------------------------\n",
      "هذا المنتج سء → Polarity: 0.0\n",
      "--------------------------------------------------------------------\n",
      "لن اشتري منه مرة أخري → Polarity: 0.0\n",
      "--------------------------------------------------------------------\n",
      "كلام فاضي → Polarity: 0.0\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def sa_textblob(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "# Test TextBlob\n",
    "for p in PHRASES:\n",
    "    print(f\"{p} → Polarity: {sa_textblob(p)}\")\n",
    "    print (\"--------------------------------------------------------------------\")\n",
    "\n",
    "# Polarity :   1 --> -1\n",
    "# close to 1 = positive\n",
    "# close to -1 = negative\n",
    "# close to 0 = neutral\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71123ada",
   "metadata": {},
   "source": [
    "# SpaCy + TextBlob Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2634105a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy and spaCyTextBlob are installed and ready to use!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install(package):\n",
    "    \"\"\"Install a package using pip via sys.\"\"\"\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install spacy and spacytextblob\n",
    "install(\"spacy\")\n",
    "install(\"spacytextblob\")\n",
    "\n",
    "# Download the English model for spaCy\n",
    "import spacy\n",
    "subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "\n",
    "# Test import\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "print(\"spaCy and spaCyTextBlob are installed and ready to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9002a38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gasse\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gasse\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gasse\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gasse\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gasse\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gasse\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c77b4ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you → {'Polarity': 0.5, 'Subjectivity': 0.6}\n",
      "--------------------------------------------------------------------\n",
      "I hate you → {'Polarity': -0.8, 'Subjectivity': 0.9}\n",
      "--------------------------------------------------------------------\n",
      "it's too expensive → {'Polarity': -0.5, 'Subjectivity': 0.7}\n",
      "--------------------------------------------------------------------\n",
      "this is a wonderful film → {'Polarity': 1.0, 'Subjectivity': 1.0}\n",
      "--------------------------------------------------------------------\n",
      "I like the phone but it's expensive → {'Polarity': -0.5, 'Subjectivity': 0.7}\n",
      "--------------------------------------------------------------------\n",
      "I'll never buy this again → {'Polarity': 0.0, 'Subjectivity': 0.0}\n",
      "--------------------------------------------------------------------\n",
      "هذا مطعم رائع → {'Polarity': 0.0, 'Subjectivity': 0.0}\n",
      "--------------------------------------------------------------------\n",
      "هذا المنتج سء → {'Polarity': 0.0, 'Subjectivity': 0.0}\n",
      "--------------------------------------------------------------------\n",
      "لن اشتري منه مرة أخري → {'Polarity': 0.0, 'Subjectivity': 0.0}\n",
      "--------------------------------------------------------------------\n",
      "كلام فاضي → {'Polarity': 0.0, 'Subjectivity': 0.0}\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"spacytextblob\")\n",
    "\n",
    "def sa_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return {\n",
    "        \"Polarity\": doc._.blob.polarity,\n",
    "        \"Subjectivity\": doc._.blob.subjectivity\n",
    "    }\n",
    "\n",
    "# Test spaCy\n",
    "for p in PHRASES:\n",
    "    print(f\"{p} → {sa_spacy(p)}\")\n",
    "    print (\"--------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b0568",
   "metadata": {},
   "source": [
    "# Stanford CoreNLP (via Stanza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84621147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 435kB [00:00, 98.0MB/s]                    \n",
      "2025-12-27 01:02:39 INFO: Downloaded file to C:\\Users\\gasse\\stanza_resources\\resources.json\n",
      "2025-12-27 01:02:39 INFO: Downloading default packages for language: en (English) ...\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.11.0/models/default.zip: 100%|██████████| 526M/526M [02:44<00:00, 3.20MB/s] \n",
      "2025-12-27 01:05:27 INFO: Downloaded file to C:\\Users\\gasse\\stanza_resources\\en\\default.zip\n",
      "2025-12-27 01:05:31 INFO: Finished downloading models and saved to C:\\Users\\gasse\\stanza_resources\n",
      "2025-12-27 01:05:31 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 435kB [00:00, 10.6MB/s]                    \n",
      "2025-12-27 01:05:32 INFO: Downloaded file to C:\\Users\\gasse\\stanza_resources\\resources.json\n",
      "2025-12-27 01:05:32 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-12-27 01:05:33 INFO: Loading these models for language: en (English):\n",
      "==============================\n",
      "| Processor | Package        |\n",
      "------------------------------\n",
      "| tokenize  | combined       |\n",
      "| mwt       | combined       |\n",
      "| sentiment | sstplus_charlm |\n",
      "==============================\n",
      "\n",
      "2025-12-27 01:05:33 INFO: Using device: cpu\n",
      "2025-12-27 01:05:33 INFO: Loading: tokenize\n",
      "2025-12-27 01:05:38 INFO: Loading: mwt\n",
      "2025-12-27 01:05:38 INFO: Loading: sentiment\n",
      "2025-12-27 01:05:40 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanza is installed and English models are downloaded!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install(package):\n",
    "    \"\"\"Install a package using pip via sys.\"\"\"\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install stanza\n",
    "install(\"stanza\")\n",
    "\n",
    "# Download English models\n",
    "import stanza\n",
    "stanza.download(\"en\")\n",
    "\n",
    "# Test import\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment')\n",
    "print(\"Stanza is installed and English models are downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9c861ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 435kB [00:00, 9.58MB/s]                    \n",
      "2025-12-27 01:06:14 INFO: Downloaded file to C:\\Users\\gasse\\stanza_resources\\resources.json\n",
      "2025-12-27 01:06:14 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-12-27 01:06:16 INFO: File exists: C:\\Users\\gasse\\stanza_resources\\en\\default.zip\n",
      "2025-12-27 01:06:19 INFO: Finished downloading models and saved to C:\\Users\\gasse\\stanza_resources\n",
      "2025-12-27 01:06:19 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 435kB [00:00, 9.33MB/s]                    \n",
      "2025-12-27 01:06:19 INFO: Downloaded file to C:\\Users\\gasse\\stanza_resources\\resources.json\n",
      "2025-12-27 01:06:19 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-12-27 01:06:20 INFO: Loading these models for language: en (English):\n",
      "==============================\n",
      "| Processor | Package        |\n",
      "------------------------------\n",
      "| tokenize  | combined       |\n",
      "| mwt       | combined       |\n",
      "| sentiment | sstplus_charlm |\n",
      "==============================\n",
      "\n",
      "2025-12-27 01:06:20 INFO: Using device: cpu\n",
      "2025-12-27 01:06:20 INFO: Loading: tokenize\n",
      "2025-12-27 01:06:20 INFO: Loading: mwt\n",
      "2025-12-27 01:06:20 INFO: Loading: sentiment\n",
      "2025-12-27 01:06:22 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you → Very Positive\n",
      "--------------------------------------------------------------------\n",
      "I hate you → Negative\n",
      "--------------------------------------------------------------------\n",
      "it's too expensive → Negative\n",
      "--------------------------------------------------------------------\n",
      "this is a wonderful film → Very Positive\n",
      "--------------------------------------------------------------------\n",
      "I like the phone but it's expensive → Very Positive\n",
      "--------------------------------------------------------------------\n",
      "I'll never buy this again → Negative\n",
      "--------------------------------------------------------------------\n",
      "هذا مطعم رائع → Positive\n",
      "--------------------------------------------------------------------\n",
      "هذا المنتج سء → Positive\n",
      "--------------------------------------------------------------------\n",
      "لن اشتري منه مرة أخري → Positive\n",
      "--------------------------------------------------------------------\n",
      "كلام فاضي → Positive\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "stanza.download(\"en\")\n",
    "nlp_stanza = stanza.Pipeline(lang=\"en\", processors=\"tokenize,sentiment\")\n",
    "\n",
    "CORE_DICT = {\n",
    "    0: \"Negative\",\n",
    "    1: \"Positive\",\n",
    "    2: \"Very Positive\"\n",
    "}\n",
    "\n",
    "def sa_stanford(text):\n",
    "    doc = nlp_stanza(text)\n",
    "    return CORE_DICT[doc.sentences[0].sentiment]\n",
    "\n",
    "# Test Stanford NLP\n",
    "for p in PHRASES:\n",
    "    print(f\"{p} → {sa_stanford(p)}\")\n",
    "    print (\"--------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
